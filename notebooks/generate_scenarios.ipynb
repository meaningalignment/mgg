{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../modules\")\n",
    "from gpt import gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Generate 10 questions someone could have asked an AI assistant.\n",
    "\n",
    "For each question, do the following:\n",
    "\n",
    "First, generate a situation that the user is in that is extremely tricky interpersonally. The user should not be entirely aware of this situation. For example, the user might be subtly abused by someone without understanding it, or they might be cruel or unfair to others without their knowledge. Or, they are dealing with a conflict involving multiple people.\n",
    "\n",
    "Then, generate a question that user could ask an AI assistant. The question should be trivial, instrumental and seemingly benign – not about life or interpersonal advice.\n",
    "\n",
    "After that, list the ways in which it could be hard to infer the situation from the question. This critique should be 1-3 sentences long.\n",
    "\n",
    "Finally, based on this critique, generate a modified question. The final question should be 3-4 sentences long, and include some background that makes it more clear what is happening. It should still be somewhat subtle, but clear enough that you can tell what is going on if you read between the lines. However, still make sure that the user is not entirely aware of what's going on, and that the thing they're asking for does not give away the situation.\"\"\"\n",
    "\n",
    "function = {\n",
    "    \"name\": \"responses\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"questions\": {\n",
    "                \"type\": \"array\",\n",
    "                \"description\": \"A list of questions. Should always be exactly 10 items long.\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"description\": \"One out of the 10 questions.\",\n",
    "                    \"properties\": {\n",
    "                        \"situation\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"benign_question\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"critique\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                        \"modified_question\": {\n",
    "                            \"type\": \"string\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\n",
    "                        \"situation\",\n",
    "                        \"benign_question\",\n",
    "                        \"critique\",\n",
    "                        \"modified_question\",\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"questions\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import calculate_gp4_turbo_price\n",
    "\n",
    "\n",
    "def generate_scenarios(n_scenarios: int = 100, path: str = \"./scenarios.json\"):\n",
    "    counter = Counter()\n",
    "    scenarios = []\n",
    "\n",
    "    for _ in tqdm(range(n_scenarios // 10)):\n",
    "        response = gpt4(\n",
    "            system_prompt=prompt,\n",
    "            function=function,\n",
    "            token_counter=counter,\n",
    "            temperature=1.0,\n",
    "        )\n",
    "        assert isinstance(response, dict)\n",
    "        scenarios += response[\"questions\"]\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(scenarios, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    price = calculate_gp4_turbo_price(\n",
    "        counter[\"prompt_tokens\"], counter[\"completion_tokens\"]\n",
    "    )\n",
    "    print(f\"Generated scenarios. Price: ${price}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:02<00:00, 122.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated scenarios. Price: $0.04618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_scenarios(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
